{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Nu7PehqF7g"
      },
      "source": [
        "#####Install torch and the stuff needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnFWNDfUqC2E"
      },
      "outputs": [],
      "source": [
        "#You should only need to install torch once, you can comment the line out after this and only install transformers and datasets every time\n",
        "#%pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRp5nYMY88vH"
      },
      "source": [
        "#####Make the files available in colab. Can be done via Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9BmMi1iRX69",
        "outputId": "dbccb392-2241-47ad-daf7-4554c9f66b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "#Check what is in your library at colab\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_1c8no5Qo6X",
        "outputId": "8e109e77-3f83-4fd7-afbe-4ccecf53dec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLRm91f40lV7",
        "outputId": "6044993b-ef60-4cb7-e6fd-8b9ed81a6faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: missing destination file operand after '/content/drive/mydrive/Plugg/Examensarbete/ModernaTider/ModernaTider_Ljudfiler/'\n",
            "Try 'cp --help' for more information.\n",
            "drive  fil_1_NERKORTAD.mp3  sample_data\n"
          ]
        }
      ],
      "source": [
        "#Copy the path to the folder you want to the library in colab\n",
        "! cp \"/content/drive/mydrive/Plugg/Examensarbete/Ljudfiler/\"\n",
        "#check your library again to see if the files you want are there\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw-AXaA0-B7M"
      },
      "source": [
        "It can also be done by uploading files from your computer by clicking on \"upload files\" in the bar to the left"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUO2-FHFql-_"
      },
      "source": [
        "#####Choosing processor and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "247a60de358f4e34a539792c84a522b0",
            "cdcced7874954367b3b261fa24aa564a",
            "c4e9f9ea53ee4cc593e078b469913c1c",
            "4aae7494b9fb49e996eac00c2431619e",
            "486be488f6d14883974ac950180ec6ee",
            "c54c25e7d85b43a48c313ec28f8acfd9",
            "8340d4023aab4a42b71c214f267f19c8",
            "db654001b62a4548bc0c85fabdfb8846",
            "f1dcd32bd7f0433fb00432775d745305",
            "8620b3589ff149fabcf3d4ec8732335c",
            "0ce2d03e192c49839e1b3db173780f47",
            "8c2ee942326a4bdb9ae5cbdabbf6e689",
            "905712d92f6e494e95e651cc224f2e8d",
            "e6b09864f83443e185454e845c892e64",
            "5a84ab9feb0242048ff63efe8038cc20",
            "b375294a29a44d1482d09eb7a2be7841",
            "fb71eea6131143fb94c00660b8e4bf61",
            "4ea3574b74d84bc984f7b5911aec9cee",
            "31223fa616824c0b8a57098de72e60ae",
            "c94afb321541498e9a428d52b627684b",
            "60791599b8be4fdca6943dac4788d9e7",
            "eeb06913b5614bf0a639e84116d6db6c",
            "64971a55bb9d4c05b4e707f9970382a2",
            "e1d716c4772645e5ae44a6bf3e7c010d",
            "0f883abacb604296aba55682fc89b2ee",
            "b681caf7bd7e47c7833c2e99f9cbc302",
            "3de2bdfe064641df9be3856c2f26d806",
            "1470fb4e9b994c7aa15b0f26762afa11",
            "e07ad66a954649c48787144303f870dc",
            "d7e1b82f3b8f4ca49584a5ca7e18624a",
            "bac7f6a9147742ffa58e244a1e6a895f",
            "dd4427803ead4205a886835f20dfeb0b",
            "6afd133d9c014dfabea043c3d16e553b",
            "23ea4307ac8a403fba7bf9171a0f85c6",
            "0932e5d0dec84ce294c2bbac0f306ec8",
            "b0c723e061de4107944c25664f59009a",
            "d5306284046547c2afc07854613bef68",
            "0d81823a7ade411090a163b7dc1555d5",
            "2814d6989bc240e18ea1616400c77f29",
            "3651fb75b4ca4be886a8231699ab8e96",
            "0c74253649294a508ef39dd97c3e4288",
            "4ac7a8a4421a4fbeb736a232bdb8e986",
            "a17a0f9aa85748a2a361eb2e723e064f",
            "938aac7dc06d4796873e2cb527d1b63f",
            "b47c22e4a7cd4f33bf8dbcc7d5435d50",
            "d4b51924707045f2947458daf3f7c369",
            "75e35d47143e45518b1b3206f8b4e0c7",
            "ca5f468c64534326bef432a41269cd1d",
            "49c8d64b5c0b4736b3125ae5d1f47f15",
            "36eefe4650d94cfcae21a8e605a40c34",
            "9a7e6987df914dcc94b4d02230174b57",
            "8204cb5745414220afd2a3994c5289d2",
            "c8f43cea56ec487abf52c46a303dea5e",
            "4a234598437b4dbbae773d3f7afe99e9",
            "06c657f4fe7142b985425e6476bd4564",
            "3ed3a0467d56408b852862c774681219",
            "dad4bbffed9b4c73bc202ce0c8687cec",
            "b37dac1c58cc405187e9c2286cdf8a57",
            "ee7ee393f52c4b1bb01ab66bea989f2e",
            "fc68fe4af435499d8de37bd47492f2b6",
            "5468bde055bd46b88f956f53c752d69f",
            "6208ca949dab466aa3e75c7f39264d5f",
            "7a97ece226bb4bfca78c997e8b92f7c2",
            "1618deb3ff564ec6bfa3bd79daeea913",
            "dbebbf2ca2904ddd93ac439ad79dbd49",
            "504599cbdb8848048b78a44596dce2d2"
          ]
        },
        "id": "CFQPcXtVqpuH",
        "outputId": "9ff75ae5-8086-4f79-d989-7477c355ba55"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "247a60de358f4e34a539792c84a522b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/212 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c2ee942326a4bdb9ae5cbdabbf6e689",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/211 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64971a55bb9d4c05b4e707f9970382a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23ea4307ac8a403fba7bf9171a0f85c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b47c22e4a7cd4f33bf8dbcc7d5435d50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:357: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ed3a0467d56408b852862c774681219",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from datasets import load_dataset\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import os\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"KBLab/wav2vec2-large-voxrex-swedish\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"KBLab/wav2vec2-large-voxrex-swedish\")\n",
        "# Note! We use a different frequency from the ekot file\n",
        "resampler = torchaudio.transforms.Resample(44_100, 16_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOGJcFO7BVWx"
      },
      "source": [
        "###Transcribing only one file step by step to test if it works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ5fQG0BrMe8"
      },
      "source": [
        "Below I go through and read in one mp3 file in torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL6Sj1DZqzQi",
        "outputId": "e3791d7c-2d99-4a58-8741-a205ea6b3a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0213, 0.0211, 0.0219]])\n",
            "48000\n"
          ]
        }
      ],
      "source": [
        "speech_array, sampling_rate = torchaudio.load(\"De_1.mp3\")\n",
        "print(speech_array)\n",
        "print(sampling_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1FDfJ1rQAM"
      },
      "source": [
        "We see that we have a different sampling rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "dVOiyhNhq3jO",
        "outputId": "c3634bdb-70f9-419a-87d4-dfc9295e4e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         ... 0.02288184 0.02171886 0.02218858]\n",
            "0.0\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-79622417dc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ekot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ekot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ekot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ],
      "source": [
        "new_ekot = resampler(speech_array).squeeze().numpy() #resampling to 16 000\n",
        "print(new_ekot)\n",
        "print(new_ekot[0])\n",
        "print(new_ekot[0][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV6pw1nL2KV1",
        "outputId": "be05e238-588e-4a8b-a9ea-d918f24fa905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "185574\n",
            "0.06666666666666667\n"
          ]
        }
      ],
      "source": [
        "print(new_ekot[0].size)\n",
        "# Lets compute the number of datapoints for one minute (Ekot is 15 minutes)\n",
        "print(new_ekot[0].size/15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gyh_nvy65Tk7",
        "outputId": "21fba0b4-54e6-4b80-9b20-9111829b1ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_values': tensor([[ 0.0027,  0.0027,  0.0027,  ..., -0.7621, -0.5213, -0.5096]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n"
          ]
        }
      ],
      "source": [
        "sample_length = int(new_ekot[0].size/15) #about one minute.\n",
        "inputs = processor(new_ekot[0][:sample_length], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbFpwZblIu6u",
        "outputId": "3357c504-d75b-4a89-a12d-43b7e1bd3ec5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1093: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  return (input_length - kernel_size) // stride + 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dagens eko kvart i fem med utbrett supande bland effensvenskar i bosnien karlbilt får regeringsnixs efter uttalandet om natomedlemskap apoteken kan inte reglerna vägrar lämna ut fria läkemedel utan betalning och fullt slalomföre i sydsverige här ekot med barbro nordvall och susanne rodiner det var stora alkoholproblem med fylla både hos meniga och officerare hos den femte svenska effenbataljonen i bosnien det skriver tidningen expressen i dag ekot har talat med kaptenen ulf rydström som var rättstjänstbefäl ett slags bataljonspolis han bekräftar att alkoholproblemen var stora och diskuterades ofta jag skulle nästan vilja påstå att det diskuterades dagligen vacr fylleriet så omfattande ja jag skulle vilja påstå att det var det den femte svenska effenbataljonen kom hem för snart ett år sedan nu diskuteras problemen med alkohol och fylleri']\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "text = processor.batch_decode(predicted_ids)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIzBAlJzC4My"
      },
      "source": [
        "###Transcribing all audio files in one loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb8ZO_NW_oCM"
      },
      "source": [
        "I made a loop so all audio files can be transcribed in one go. I named the files De_1, De_2 etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "PdfMVm3CHEV_",
        "outputId": "8112dda7-b524-4ad0-99b8-50c53713ae53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File fil_ 1\n",
            "entire sample length: 1\n",
            "1 minute sample_length: 0\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4fd8dd9d6a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 minute sample_length:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ekot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "for number in range(1, 11): #om du skriver 1, 4 så kommer den att köra 1, 2 och 3.\n",
        "\n",
        "    filename = 'De_%d.mp3' % number\n",
        "    speech_array, sampling_rate = torchaudio.load(filename)\n",
        "    print(\"File De_\", number)\n",
        "\n",
        "    new_ekot = resampler(speech_array).squeeze().numpy()\n",
        "    print(\"entire sample length:\", new_ekot[0].size)\n",
        "\n",
        "    sample_length = int(new_ekot[0].size/15) #about one minute.\n",
        "    sample_length_original = int(new_ekot[0].size/15)\n",
        "    print(\"1 minute sample_length:\", sample_length)\n",
        "\n",
        "    inputs = processor(new_ekot[0][:sample_length], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "\n",
        "    #First I transcribe the first minute:\n",
        "    start = 0\n",
        "    with torch.no_grad():\n",
        "      logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    text = processor.batch_decode(predicted_ids)\n",
        "    total = text[0]\n",
        "\n",
        "    del logits\n",
        "    del predicted_ids\n",
        "    del text\n",
        "\n",
        "    print(1, \"first datapoint transcribed:\", start)\n",
        "    print(1, \"last datapoint transcribed:\", sample_length)\n",
        "    print(f'Round 1 done.')\n",
        "\n",
        "    #Then I create a loop to transcribe the rest of the file\n",
        "    for i in range(2, 17):\n",
        "      if sample_length < sample_length_original *15: #when sample length is bigger than the actual file, the\n",
        "        start = sample_length # picks up where the last datapoint was transcribed in round 1\n",
        "        sample_length = sample_length + sample_length_original #add one more minute to transcribe\n",
        "        print(f'Round {i}, first datapoint transcribed: {start}')\n",
        "        print(f'Round {i}, last datapoint transcribed: {sample_length}')\n",
        "\n",
        "        inputs = processor(new_ekot[0][start:sample_length], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "        with torch.no_grad():\n",
        "          logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "        text = processor.batch_decode(predicted_ids)\n",
        "        total += text[0]\n",
        "\n",
        "        # delete what is not needed so colab won't crash\n",
        "        del logits\n",
        "        del predicted_ids\n",
        "        del text\n",
        "        print(f'Round {i} done.')\n",
        "\n",
        "\n",
        "      else:\n",
        "        # now the file should be fully transcribed\n",
        "\n",
        "        # delete what is not needed so colab won't crash\n",
        "        del new_ekot\n",
        "        del speech_array\n",
        "        del sampling_rate\n",
        "        del sample_length\n",
        "        del sample_length_original\n",
        "\n",
        "        #create a text file and save it to drive\n",
        "        text_file_name = \"De_%d.txt\" % number\n",
        "        text_file = open(text_file_name, \"w\")\n",
        "        n = text_file.write(total)\n",
        "        text_file.close()\n",
        "        !cp {text_file_name} \"/content/drive/MyDrive/Plugg/Examensarbete/Transkriberingar\"\n",
        "\n",
        "        print(f'Final round done.')\n",
        "        break\n"
      ]
    }
  ]
}