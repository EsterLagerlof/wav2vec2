{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Nu7PehqF7g"
      },
      "source": [
        "#####Install torch and the stuff needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnFWNDfUqC2E"
      },
      "outputs": [],
      "source": [
        "#You should only need to install torch once, you can comment the line out after this and only install transformers and datasets every time\n",
        "%pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRp5nYMY88vH"
      },
      "source": [
        "#####Make the files available in colab. Can be done via Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9BmMi1iRX69"
      },
      "outputs": [],
      "source": [
        "#Check what is in your library at colab\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_1c8no5Qo6X"
      },
      "outputs": [],
      "source": [
        "#Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLRm91f40lV7"
      },
      "outputs": [],
      "source": [
        "#Copy the path to the folder you want to the library in colab\n",
        "! cp \"/content/drive/mydrive/Plugg/Examensarbete/Ljudfiler/\"\n",
        "#check your library again to see if the files you want are there\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw-AXaA0-B7M"
      },
      "source": [
        "It can also be done by uploading files from your computer by clicking on \"upload files\" in the bar to the left"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUO2-FHFql-_"
      },
      "source": [
        "#####Choosing processor and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFQPcXtVqpuH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from datasets import load_dataset\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import os\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"KBLab/wav2vec2-large-voxrex-swedish\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"KBLab/wav2vec2-large-voxrex-swedish\")\n",
        "# Note! We use a different frequency from the ekot file\n",
        "resampler = torchaudio.transforms.Resample(44_100, 16_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOGJcFO7BVWx"
      },
      "source": [
        "###Transcribing only one file step by step to test if it works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ5fQG0BrMe8"
      },
      "source": [
        "Below I go through and read in one mp3 file in torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL6Sj1DZqzQi"
      },
      "outputs": [],
      "source": [
        "speech_array, sampling_rate = torchaudio.load(\"De_1.mp3\")\n",
        "print(speech_array)\n",
        "print(sampling_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1FDfJ1rQAM"
      },
      "source": [
        "We see that we have a different sampling rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVOiyhNhq3jO"
      },
      "outputs": [],
      "source": [
        "new_ekot = resampler(speech_array).squeeze().numpy() #resampling to 16 000\n",
        "print(new_ekot)\n",
        "print(new_ekot[0])\n",
        "print(new_ekot[0][:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV6pw1nL2KV1"
      },
      "outputs": [],
      "source": [
        "print(new_ekot[0].size)\n",
        "# Lets compute the number of datapoints for one minute (Ekot is 15 minutes)\n",
        "print(new_ekot[0].size/15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyh_nvy65Tk7"
      },
      "outputs": [],
      "source": [
        "sample_length = int(new_ekot[0].size/15) #about one minute.\n",
        "inputs = processor(new_ekot[0][:sample_length], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbFpwZblIu6u"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "text = processor.batch_decode(predicted_ids)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIzBAlJzC4My"
      },
      "source": [
        "###Transcribing all audio files in one loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb8ZO_NW_oCM"
      },
      "source": [
        "I made a loop so all audio files can be transcribed in one go. I named the files De_1, De_2 etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdfMVm3CHEV_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "for number in range(1, 44): #If you write (1, 4), it will run 1 through 3.\n",
        "\n",
        "    filename = 'De_%d.mp3' % number\n",
        "    speech_array, sampling_rate = torchaudio.load(filename)\n",
        "    print(\"File De_\", number)\n",
        "\n",
        "    new_ekot = resampler(speech_array).squeeze().numpy()\n",
        "    print(\"entire sample length:\", new_ekot[0].size)\n",
        "\n",
        "    sample_length = int(new_ekot[0].size/15) #about one minute.\n",
        "    sample_length_original = int(new_ekot[0].size/15)\n",
        "    print(\"1 minute sample_length:\", sample_length)\n",
        "\n",
        "    inputs = processor(new_ekot[0][:sample_length], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "\n",
        "    #First I transcribe the first minute:\n",
        "    start = 0\n",
        "    with torch.no_grad():\n",
        "      logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    text = processor.batch_decode(predicted_ids)\n",
        "    total = text[0]\n",
        "\n",
        "    del logits\n",
        "    del predicted_ids\n",
        "    del text\n",
        "\n",
        "    print(1, \"first datapoint transcribed:\", start)\n",
        "    print(1, \"last datapoint transcribed:\", sample_length)\n",
        "    print(f'Round 1 done.')\n",
        "\n",
        "    #Then I create a loop to transcribe the rest of the file\n",
        "    for i in range(2, 17):\n",
        "      if sample_length < sample_length_original *15: #when sample length is bigger than the actual file, the\n",
        "        start = sample_length # picks up where the last datapoint was transcribed in round 1\n",
        "        sample_length = sample_length + sample_length_original #add one more minute to transcribe\n",
        "        print(f'Round {i}, first datapoint transcribed: {start}')\n",
        "        print(f'Round {i}, last datapoint transcribed: {sample_length}')\n",
        "\n",
        "        inputs = processor(new_ekot[0][start:sample_length], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "        with torch.no_grad():\n",
        "          logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "        text = processor.batch_decode(predicted_ids)\n",
        "        total += text[0]\n",
        "\n",
        "        # delete what is not needed so colab won't crash\n",
        "        del logits\n",
        "        del predicted_ids\n",
        "        del text\n",
        "        print(f'Round {i} done.')\n",
        "\n",
        "\n",
        "      else:\n",
        "        # now the file should be fully transcribed\n",
        "\n",
        "        # delete what is not needed so colab won't crash\n",
        "        del new_ekot\n",
        "        del speech_array\n",
        "        del sampling_rate\n",
        "        del sample_length\n",
        "        del sample_length_original\n",
        "\n",
        "        #create a text file and save it to drive\n",
        "        text_file_name = \"De_%d.txt\" % number\n",
        "        text_file = open(text_file_name, \"w\")\n",
        "        n = text_file.write(total)\n",
        "        text_file.close()\n",
        "        !cp {text_file_name} \"/content/drive/MyDrive/Plugg/Examensarbete/Transkriberingar\"\n",
        "\n",
        "        print(f'Final round done.')\n",
        "        break\n"
      ]
    }
  ]
}